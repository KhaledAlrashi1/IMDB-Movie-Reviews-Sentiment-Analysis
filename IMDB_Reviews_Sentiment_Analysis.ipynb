{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis of IMDB Reviews using LSTM","metadata":{"id":"UtpaWCrLHOoj"}},{"cell_type":"markdown","source":"# Table of Contents\n\n1. [Data Preparation and Visualization](#Data-Preparation-and-Visualization)\n    - [Loading the Dataset]\n    - [Word Frequency Analysis]\n    - [Review Length Analysis]\n    - [Word Clouds for Reviews]\n2. [Building and Training the LSTM Model](#Building-and-Training-the-LSTM-Model)\n    - [Model Architecture]\n    - [Model Training]\n3. [Evaluating Model Performance](#Evaluating-Model-Performance)\n    - [Loss and Accuracy Plots]\n    - [Confusion Matrix]\n    - [Sample Predictions]","metadata":{"id":"kUIvncs-M8H4"}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"# TensorFlow and Keras for building the neural network\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n# Matplotlib for plotting, Seaborn for advanced visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# WordCloud for text visualization\nfrom wordcloud import WordCloud\n# NumPy for numerical operations\nimport numpy as np\nfrom collections import Counter\n# Sklearn for model evaluation metrics,\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.preprocessing.text import Tokenizer\nimport pandas as pd\nimport string","metadata":{"id":"SNYHR3vMHLwN","execution":{"iopub.status.busy":"2023-12-18T03:57:56.363596Z","iopub.execute_input":"2023-12-18T03:57:56.364231Z","iopub.status.idle":"2023-12-18T03:57:56.373594Z","shell.execute_reply.started":"2023-12-18T03:57:56.364166Z","shell.execute_reply":"2023-12-18T03:57:56.372110Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"Data-Preparation-and-Visualization\"></a>\n# Data Preparation and Visualization\n---","metadata":{"id":"z0f4KAU4HSZc"}},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T03:54:07.370416Z","iopub.execute_input":"2023-12-18T03:54:07.370915Z","iopub.status.idle":"2023-12-18T03:54:08.134472Z","shell.execute_reply.started":"2023-12-18T03:54:07.370874Z","shell.execute_reply":"2023-12-18T03:54:08.133028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T03:54:08.135972Z","iopub.execute_input":"2023-12-18T03:54:08.136342Z","iopub.status.idle":"2023-12-18T03:54:08.144727Z","shell.execute_reply.started":"2023-12-18T03:54:08.136301Z","shell.execute_reply":"2023-12-18T03:54:08.143358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sentiment.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T03:54:08.174623Z","iopub.execute_input":"2023-12-18T03:54:08.175106Z","iopub.status.idle":"2023-12-18T03:54:08.191230Z","shell.execute_reply.started":"2023-12-18T03:54:08.175070Z","shell.execute_reply":"2023-12-18T03:54:08.190188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine all reviews into a single string\nall_reviews = ' '.join(df['review'])\n# Convert to lowercase\nall_reviews = all_reviews.lower()\n# Remove punctuation\nall_reviews = all_reviews.translate(str.maketrans('', '', string.punctuation))\n# Tokenize (split the reviews into words)\nwords = all_reviews.split()\n# Count the word frequencies\nword_freq = Counter(words)\n# Most common words\nmost_common_words = word_freq.most_common(20)\n\n# Extracting words and their frequencies for plotting\nwords, frequencies = zip(*most_common_words)\n\n# Creating a bar plot\nplt.figure(figsize=(12, 8))\nplt.bar(words, frequencies)\nplt.xlabel('Words')\nplt.ylabel('Frequency')\nplt.title('Top 20 Most Common Words in IMDB Reviews')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T03:54:08.589642Z","iopub.execute_input":"2023-12-18T03:54:08.590142Z","iopub.status.idle":"2023-12-18T03:54:20.950905Z","shell.execute_reply.started":"2023-12-18T03:54:08.590103Z","shell.execute_reply":"2023-12-18T03:54:20.948021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Review Length Analysis\n# Calculate the number of words in each review\nreview_word_counts = df['review'].apply(lambda review: len(review.split()))\n\n# Plotting the distribution of review word counts\nplt.figure(figsize=(10, 5))\nplt.hist(review_word_counts, bins=50, color='blue', alpha=0.7)\nplt.title('Distribution of Review Word Counts in IMDB Reviews')\nplt.xlabel('Review Word Count')\nplt.ylabel('Number of Reviews')\nplt.show()\n\n# Calculate mean and median of review word counts\nmean_word_count = np.mean(review_word_counts)\nmedian_word_count = np.median(review_word_counts)\nprint(\"Mean review word count:\", mean_word_count)\nprint(\"Median review word count:\", median_word_count)","metadata":{"id":"SXgNNqPLHc1s","outputId":"fdb96404-9b5e-4754-aee8-725cff2fdb52","execution":{"iopub.status.busy":"2023-12-18T03:54:20.954055Z","iopub.execute_input":"2023-12-18T03:54:20.954711Z","iopub.status.idle":"2023-12-18T03:54:22.334529Z","shell.execute_reply.started":"2023-12-18T03:54:20.954668Z","shell.execute_reply":"2023-12-18T03:54:22.333222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n\n# Calculate word counts in reviews\ndf['word_count'] = df['review'].apply(lambda x: len(x.split()))\n\n# Separate word counts for positive and negative reviews\npositive_word_counts = df[df['label'] == 1]['word_count']\nnegative_word_counts = df[df['label'] == 0]['word_count']\n\n# Plotting\nplt.figure(figsize=(10, 5))\nplt.hist(positive_word_counts, bins=20, alpha=0.7, label='Positive Reviews', color='green')\nplt.hist(negative_word_counts, bins=20, alpha=0.7, label='Negative Reviews', color='red')\nplt.xlabel('Review Word Count')\nplt.ylabel('Number of Reviews')\nplt.title('Word Count Distribution of Positive vs. Negative Reviews')\nplt.legend()\nplt.show()\n","metadata":{"id":"w_TbjABbJF-J","outputId":"fe4f7d59-9987-4d39-de24-510dc279e276","execution":{"iopub.status.busy":"2023-12-18T03:54:22.336180Z","iopub.execute_input":"2023-12-18T03:54:22.336567Z","iopub.status.idle":"2023-12-18T03:54:23.721279Z","shell.execute_reply.started":"2023-12-18T03:54:22.336533Z","shell.execute_reply":"2023-12-18T03:54:23.719780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to Generate Word Cloud\ndef generate_word_cloud(text_data):\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(text_data))\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()\n\ndf['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})","metadata":{"execution":{"iopub.status.busy":"2023-12-18T03:54:23.724602Z","iopub.execute_input":"2023-12-18T03:54:23.725164Z","iopub.status.idle":"2023-12-18T03:54:23.743948Z","shell.execute_reply.started":"2023-12-18T03:54:23.725117Z","shell.execute_reply":"2023-12-18T03:54:23.741967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating Word Clouds for Positive Reviews\npositive_reviews = df[df['label'] == 1]['review']\nprint(\"Word Cloud for Positive Reviews\")\ngenerate_word_cloud(positive_reviews)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T03:54:23.747924Z","iopub.execute_input":"2023-12-18T03:54:23.749502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating Word Clouds for Negative Reviews\nnegative_reviews = df[df['label'] == 0]['review']\nprint(\"Word Cloud for Negative Reviews\")\ngenerate_word_cloud(negative_reviews)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"Building-and-Training-the-LSTM-Model\"></a>\n## Building and Training the LSTM Model\n---\n\n","metadata":{"id":"sR-ppITWHiQn"}},{"cell_type":"code","source":"reviews = df['review'].values\nlabels = df['sentiment'].values\nlabels = df['sentiment'].map({'positive': 1, 'negative': 0}).values\n\n# Tokenizing the text\ntokenizer = Tokenizer(num_words=10000)  # Adjust num_words as needed\ntokenizer.fit_on_texts(reviews)\nsequences = tokenizer.texts_to_sequences(reviews)\n\n# Padding the sequences\nmax_len = 350  # Length is chosen based on analysis of review lengths\ndata_padded = pad_sequences(sequences, maxlen=max_len)\ntrain_data, test_data, train_labels, test_labels = train_test_split(data_padded, labels, test_size=0.5, random_state=42)\n\n# # Splitting the data into train and test sets\n# train_data, test_data, train_labels, test_labels = train_test_split(data_padded, labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T03:28:41.888492Z","iopub.execute_input":"2023-12-18T03:28:41.889017Z","iopub.status.idle":"2023-12-18T03:29:09.212437Z","shell.execute_reply.started":"2023-12-18T03:28:41.888963Z","shell.execute_reply":"2023-12-18T03:29:09.210954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining the LSTM Model\n# The model consists of an Embedding layer, an LSTM layer, and a Dense output layer\nmodel = Sequential([\n    Embedding(10000, 16, input_length=max_len),  # Turns positive integers (indexes) into dense vectors of fixed size\n    LSTM(32, dropout=0.3),  # LSTM layer with 32 units and 30% dropout for regularization\n    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n])\n\n# Compile the Model\n# RMSprop optimizer is used with binary crossentropy loss, as it's a binary classification problem\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n\n# Training the Model\n# The model is trained for 10 epochs with a batch size of 128\n# 20% of the training data is used as a validation set to monitor the model's performance\nmodel_checkpoint = ModelCheckpoint('trained_model.h5', save_best_only=True)\nhistory = model.fit(train_data, train_labels, epochs=10, batch_size=128, validation_split=0.2, callbacks=[model_checkpoint])","metadata":{"id":"86qnfu-xHeMQ","outputId":"4c3ecd17-d725-416c-d572-94d2bb4960d6","execution":{"iopub.status.busy":"2023-12-18T03:29:09.216870Z","iopub.execute_input":"2023-12-18T03:29:09.217736Z","iopub.status.idle":"2023-12-18T03:34:52.460665Z","shell.execute_reply.started":"2023-12-18T03:29:09.217683Z","shell.execute_reply":"2023-12-18T03:34:52.459450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"Evaluating-Model-Performance\"></a>\n# Evaluating Model Performance\n---","metadata":{"id":"RVvgrn5nIKN4"}},{"cell_type":"code","source":"# Evaluate model on test data\nloss, accuracy = model.evaluate(test_data, test_labels)\nprint(f\"Test Accuracy: {accuracy*100:.2f}%\")","metadata":{"id":"R-Vkig5nIKiw","outputId":"8d8a3836-8624-4300-b6ac-a7a8cdc14ce0","execution":{"iopub.status.busy":"2023-12-18T03:34:52.463531Z","iopub.execute_input":"2023-12-18T03:34:52.464168Z","iopub.status.idle":"2023-12-18T03:35:23.399096Z","shell.execute_reply.started":"2023-12-18T03:34:52.464126Z","shell.execute_reply":"2023-12-18T03:35:23.398048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting Loss per Epoch\n# Training Loss and Validation Loss are plotted to understand the learning trends\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss per Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plotting Accuracy per Epoch\n# Training Accuracy and Validation Accuracy are plotted for performance insights\nplt.subplot(1, 2, 2)\nplt.plot(history.history['acc'], label='Training Accuracy')\nplt.plot(history.history['val_acc'], label='Validation Accuracy')\nplt.title('Accuracy per Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"id":"YW9AhYopIUIQ","outputId":"694f6e0d-e361-4ead-ac61-37fa44e3fdf4","execution":{"iopub.status.busy":"2023-12-18T03:35:23.400537Z","iopub.execute_input":"2023-12-18T03:35:23.401107Z","iopub.status.idle":"2023-12-18T03:35:24.145128Z","shell.execute_reply.started":"2023-12-18T03:35:23.401072Z","shell.execute_reply":"2023-12-18T03:35:24.143536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\n# Provides a summary of prediction results on a classification problem\n# Helpful to see the model's performance in terms of false positives, false negatives, etc.\n\n# Predicting Test Data\ny_pred_classes = (model.predict(test_data) > 0.5).astype(\"int32\")\n\n# Creating the Confusion Matrix\ncm = confusion_matrix(test_labels, y_pred_classes)\nplt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","metadata":{"id":"llC2ZjoJIXtv","outputId":"f2d884fd-5711-4f1b-e541-2f10667e6dec","execution":{"iopub.status.busy":"2023-12-18T03:35:24.147840Z","iopub.execute_input":"2023-12-18T03:35:24.148219Z","iopub.status.idle":"2023-12-18T03:35:56.664355Z","shell.execute_reply.started":"2023-12-18T03:35:24.148187Z","shell.execute_reply":"2023-12-18T03:35:56.663312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"Sample-Predictions\"></a>\n# Sample Predictions\n\n#### Making Predictions on Sample Test Data. This section showcases how the model performs on unseen data. It compares the predicted sentiment against the actual sentiment","metadata":{"id":"feDvpmsEL0Sv"}},{"cell_type":"code","source":"# Sample some test data for predictions\nsample_data = test_data[:10]\nsample_labels = test_labels[:10]  # Corresponding true labels\n\n# Model Predictions\npredictions = model.predict(sample_data)\n\n# For each prediction, determine the predicted and actual sentiment\nfor i, pred in enumerate(predictions):\n    predicted_sentiment = \"Positive\" if pred > 0.5 else \"Negative\"\n    actual_sentiment = \"Positive\" if sample_labels[i] == 1 else \"Negative\"\n    print(f\"Review {i}: Predicted Sentiment - {predicted_sentiment}, Actual Sentiment - {actual_sentiment}\")\n","metadata":{"id":"VmgR5YGRI4B7","outputId":"57efc3de-5ae2-44ba-da70-1cd37f748643","execution":{"iopub.status.busy":"2023-12-18T03:35:56.665718Z","iopub.execute_input":"2023-12-18T03:35:56.666804Z","iopub.status.idle":"2023-12-18T03:35:56.787691Z","shell.execute_reply.started":"2023-12-18T03:35:56.666755Z","shell.execute_reply":"2023-12-18T03:35:56.786655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<a id=\"Saving-and-Loading-the-Model\"></a>\n# Saving and Loading the Model","metadata":{"id":"6WaLaKZrL73e"}},{"cell_type":"code","source":"# Load the previously trained and saved model\nmodel = load_model('trained_model.h5')\n\n# Loading the IMDB dataset\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n\nmax_len = 350  # Following the training configuration\ntest_data = pad_sequences(test_data, maxlen=max_len)\n\n# Evaluate the loaded model on the test dataset\n# This is to ensure that the saved model performs as expected\nloss, accuracy = model.evaluate(test_data, test_labels)\n\n# Print the test accuracy of the loaded model\nprint(f\"Test Accuracy of the loaded model: {accuracy * 100:.2f}%\")","metadata":{"id":"5AsCnnS1Ly25","outputId":"506f9a56-b70e-400d-8deb-44b691c99fb5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"XAkbzef2RM9R"},"execution_count":null,"outputs":[]}]}